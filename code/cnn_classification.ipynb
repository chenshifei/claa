{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "cnn_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOhUnjfjzEc7",
        "colab_type": "text"
      },
      "source": [
        "# Build up the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ73tGQJzEc8",
        "colab_type": "text"
      },
      "source": [
        "## Create the Monolingual Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OCXB1lM1knM",
        "colab_type": "code",
        "outputId": "b0af01fc-180a-48d0-9277-c3e9c4ef5989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDCXdZCfzEc9",
        "colab_type": "code",
        "outputId": "15bc193b-c30d-4f43-81fb-816b31534cd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('drive/My Drive/tweets_monolingual_5p.csv')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id_str</th>\n",
              "      <th>screen_name</th>\n",
              "      <th>raw_text</th>\n",
              "      <th>chn_text</th>\n",
              "      <th>eng_text</th>\n",
              "      <th>monolingual_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1193152895337689088</td>\n",
              "      <td>YXSzzzz</td>\n",
              "      <td>@gww067 Haha there is no way Ryza is not cute 😂</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Haha there is no way Ryza is not cute</td>\n",
              "      <td>Haha there is no way Ryza is not cute</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1193152895337689088</td>\n",
              "      <td>YXSzzzz</td>\n",
              "      <td>乳不平何以平天下!\\nLess busty testing. https://t.co/Iy...</td>\n",
              "      <td>乳不平何以平天下!</td>\n",
              "      <td>Less busty testing.</td>\n",
              "      <td>乳不平何以平天下!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1193152895337689088</td>\n",
              "      <td>YXSzzzz</td>\n",
              "      <td>@HrJasn 乳不巨何以聚人心 (誤</td>\n",
              "      <td>乳不巨何以聚人心誤</td>\n",
              "      <td>NaN</td>\n",
              "      <td>乳不巨何以聚人心誤</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1193152895337689088</td>\n",
              "      <td>YXSzzzz</td>\n",
              "      <td>因為蠻多人問。。。我就統一發個 😂\\nBecuz too many people ask ....</td>\n",
              "      <td>因為蠻多人問。。。我就統一發個這個是我自己無聊畫的，不是…</td>\n",
              "      <td>Becuz too many people ask ... I will post thi...</td>\n",
              "      <td>因為蠻多人問。。。我就統一發個這個是我自己無聊畫的，不是…</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1193152895337689088</td>\n",
              "      <td>YXSzzzz</td>\n",
              "      <td>因為蠻多人問。。。我就統一發個 😂\\nBecuz too many people ask ....</td>\n",
              "      <td>因為蠻多人問。。。我就統一發個這個是我自己無聊畫的，不是…</td>\n",
              "      <td>Becuz too many people ask ... I will post thi...</td>\n",
              "      <td>Becuz too many people ask ... I will post thi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                   monolingual_text\n",
              "0           0  ...              Haha there is no way Ryza is not cute\n",
              "1           1  ...                                          乳不平何以平天下!\n",
              "2           3  ...                                          乳不巨何以聚人心誤\n",
              "3           4  ...                      因為蠻多人問。。。我就統一發個這個是我自己無聊畫的，不是…\n",
              "4           5  ...   Becuz too many people ask ... I will post thi...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gO_xT_QzEdG",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess and Split the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1nr0KUDzWUa",
        "colab_type": "code",
        "outputId": "9ea7e99d-c462-4121-a4a9-71dced05092c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "!pip3 install polyglot PyICU pycld2 morfessor"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting polyglot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/98/e24e2489114c5112b083714277204d92d372f5bbe00d5507acf40370edb9/polyglot-16.7.4.tar.gz (126kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 2.7MB/s \n",
            "\u001b[?25hCollecting PyICU\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/0c/0fb09019efb65a29789ec5538f8e521b8f548da6935a3a474e19fbf2ea4d/PyICU-2.4.2.tar.gz (219kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 7.9MB/s \n",
            "\u001b[?25hCollecting pycld2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/d2/8b0def84a53c88d0eb27c67b05269fbd16ad68df8c78849e7b5d65e6aec3/pycld2-0.41.tar.gz (41.4MB)\n",
            "\u001b[K     |████████████████████████████████| 41.4MB 211kB/s \n",
            "\u001b[?25hCollecting morfessor\n",
            "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
            "Building wheels for collected packages: polyglot, PyICU, pycld2\n",
            "  Building wheel for polyglot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for polyglot: filename=polyglot-16.7.4-py2.py3-none-any.whl size=52560 sha256=f15f5742d85d1fb191d6860e4bb7b488a001493967efd36018ffbcf44f627ef8\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/91/ef/f1369fdc1203b0a9347d4b24f149b83a305f39ab047986d9da\n",
            "  Building wheel for PyICU (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyICU: filename=PyICU-2.4.2-cp36-cp36m-linux_x86_64.whl size=1245012 sha256=437a325a6a0368b3ca12cfcfca0fc7437cb37030aa2a8141e23a46e15f55e350\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/78/89/08a15173ae1905de95ce9a5f55b17259ca5b462ed11a4c068c\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp36-cp36m-linux_x86_64.whl size=9833335 sha256=0de326da3713a3e90f29f41e33832cd07dee75fe54202d691d67d2fb1947026b\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/8f/e9/08a1a8932a490175bd140206cd86a3dbcfc70498100de11079\n",
            "Successfully built polyglot PyICU pycld2\n",
            "Installing collected packages: polyglot, PyICU, pycld2, morfessor\n",
            "Successfully installed PyICU-2.4.2 morfessor-2.0.6 polyglot-16.7.4 pycld2-0.41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgvZB7-_zEdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from polyglot.text import Text\n",
        "import logging\n",
        "\n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "def poly_tokenizer(raw_text):\n",
        "    return Text(raw_text).words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn74sv1HzEdJ",
        "colab_type": "code",
        "outputId": "5747c997-d899-4dbf-cbe2-9f8cb7cf4fc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "from torchtext.data import TabularDataset, Field, LabelField\n",
        "\n",
        "TEXT = Field(sequential=True, tokenize=ploy_tokenizer, lower=True)\n",
        "LABEL = LabelField()\n",
        "\n",
        "datafields = {'screen_name': ('label', LABEL), 'monolingual_text': ('text', TEXT)}\n",
        "tweets_dataset = TabularDataset(path='drive/My Drive/tweets_monolingual_5p.csv', format='csv', fields=datafields)\n",
        "\n",
        "vars(tweets_dataset[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10.5 s, sys: 74.6 ms, total: 10.5 s\n",
            "Wall time: 10.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxOa5y2ozEdL",
        "colab_type": "code",
        "outputId": "298f41a9-51d3-4f78-d8a8-179a38886247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data, valid_data, test_data = tweets_dataset.split(split_ratio=[0.7, 0.1, 0.2], stratified=True)\n",
        "\n",
        "print('Size of train, valid & test=', len(train_data), len(valid_data), len(test_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of train, valid & test= 48420 13830 6920\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zdx9W4lWzEdP",
        "colab_type": "text"
      },
      "source": [
        "## Load Custom Aligned Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzaNLPpLzEdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.vocab import Vocab, Vectors\n",
        "\n",
        "chn_vector = Vectors(name='drive/My Drive/embeddings/wiki.zh.align.vec')\n",
        "eng_vector = Vectors(name='drive/My Drive/embeddings/wiki.en.align.vec')\n",
        "\n",
        "TEXT.build_vocab(train_data, vectors=[chn_vector, eng_vector])\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9td6M_l1zEdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key=lambda x:len(x.text),\n",
        "    device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiqVtZ8TzEdU",
        "colab_type": "text"
      },
      "source": [
        "# CNN Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmvnYm1HzEdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv2d(in_channels = 1, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = (fs, embedding_dim)) \n",
        "                                    for fs in filter_sizes\n",
        "                                    ])\n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        text = text.permute(1, 0)\n",
        "        embedded = self.embedding(text)\n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "\n",
        "        return self.fc(cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gS3c-SMzEdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 600\n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [2,3,4,5]\n",
        "OUTPUT_DIM = len(LABEL.vocab)\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHITLY2izEdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ODmkE_azEdb",
        "colab_type": "code",
        "outputId": "916d8d96-257a-4b71-c8dc-7b05f845c0c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 34,606,250 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xy9DhS3zEdd",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXVAeb3ozEdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwudVD-LzEde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(batch.text)\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        acc = categorical_accuracy(predictions, batch.label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def categorical_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    correct = max_preds.squeeze(1).eq(y)\n",
        "    return correct.sum() / torch.FloatTensor([y.shape[0]])\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            predictions = model(batch.text)\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = categorical_accuracy(predictions, batch.label)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNvVD9ODzEdf",
        "colab_type": "code",
        "outputId": "127cd81a-bd91-41db-ae1c-e9bea561e226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "N_EPOCHS = 8\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 1m 7s\n",
            "\tTrain Loss: 0.452 | Train Acc: 87.52%\n",
            "\t Val. Loss: 1.286 |  Val. Acc: 70.92%\n",
            "Epoch: 02 | Epoch Time: 1m 6s\n",
            "\tTrain Loss: 0.239 | Train Acc: 93.16%\n",
            "\t Val. Loss: 1.437 |  Val. Acc: 70.75%\n",
            "Epoch: 03 | Epoch Time: 1m 6s\n",
            "\tTrain Loss: 0.156 | Train Acc: 95.56%\n",
            "\t Val. Loss: 1.624 |  Val. Acc: 70.44%\n",
            "Epoch: 04 | Epoch Time: 1m 7s\n",
            "\tTrain Loss: 0.116 | Train Acc: 96.60%\n",
            "\t Val. Loss: 1.790 |  Val. Acc: 69.69%\n",
            "Epoch: 05 | Epoch Time: 1m 7s\n",
            "\tTrain Loss: 0.101 | Train Acc: 97.01%\n",
            "\t Val. Loss: 1.974 |  Val. Acc: 69.56%\n",
            "Epoch: 06 | Epoch Time: 1m 6s\n",
            "\tTrain Loss: 0.089 | Train Acc: 97.43%\n",
            "\t Val. Loss: 2.128 |  Val. Acc: 69.44%\n",
            "Epoch: 07 | Epoch Time: 1m 6s\n",
            "\tTrain Loss: 0.079 | Train Acc: 97.74%\n",
            "\t Val. Loss: 2.277 |  Val. Acc: 69.23%\n",
            "Epoch: 08 | Epoch Time: 1m 6s\n",
            "\tTrain Loss: 0.072 | Train Acc: 97.97%\n",
            "\t Val. Loss: 2.538 |  Val. Acc: 68.34%\n",
            "Epoch: 09 | Epoch Time: 1m 7s\n",
            "\tTrain Loss: 0.072 | Train Acc: 97.96%\n",
            "\t Val. Loss: 2.679 |  Val. Acc: 68.95%\n",
            "Epoch: 10 | Epoch Time: 1m 6s\n",
            "\tTrain Loss: 0.064 | Train Acc: 98.19%\n",
            "\t Val. Loss: 2.855 |  Val. Acc: 68.74%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak_d85ETppwa",
        "colab_type": "code",
        "outputId": "a083ddc9-43f1-47d1-da4d-be4f73270522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.load_state_dict(torch.load('model.pt'))\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 1.304 | Test Acc: 70.68%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AymD5YoFzEdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}